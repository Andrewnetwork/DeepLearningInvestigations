{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Dense, Conv2D\n",
    "from keras.models import Model\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "from skimage.color import rgb2grey\n",
    "import os\n",
    "#print(os.listdir(\"../input/flowers-recognition/flowers/flowers/rose\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "flowerPath = \"../input/flowers-recognition/flowers/flowers/\"\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=(1/255))\n",
    "flowerGen = datagen.flow_from_directory(flowerPath,batch_size=1,target_size=(512,512),class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "04603434-b8f7-4761-8dc0-932f00cf2aad",
    "_uuid": "d069c6e84abd03ea56c18f1533884985b42cb1a0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns a tuple (greyscale_img,rgb_img)\n",
    "def flower_dat_gen(classNum,gen):\n",
    "    for img in gen:\n",
    "        if(img[1][0] == classNum):\n",
    "            #print(img[0][0].shape)\n",
    "            a = np.random.binomial(9, 0.1, 512*512)\n",
    "            print(a.shape)\n",
    "            yield a,a\n",
    "            #yield (rgb2grey(img[0][0]).flatten(),rgb2grey(img[0][0]).flatten())\n",
    "            #yield rgb2grey(img[0][0]).flatten(),img[0][0]\n",
    "def test1():\n",
    "    a = np.random.binomial(9, 0.1, 512*512)\n",
    "    yield (a,a)\n",
    "    #for i in range(10):\n",
    "    \n",
    "def visRes(predictOUt):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    r = np.array(predictOUt)[0,:,:][0]\n",
    "    g = np.array(predictOUt)[1,:,:][0]\n",
    "    b = np.array(predictOUt)[2,:,:][0]\n",
    "    plt.imshow(np.dstack((r,g,b))[0,:,:].reshape((512,512,3)))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "980cd1aa-f477-4703-a320-f8c50dd32a7e",
    "_uuid": "69bbe1a1db306f99750a65294bd76e4d9bcb8280",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xy_regression():\n",
    "    input_vect = Input(shape=(2,)) \n",
    "    \n",
    "    l1 = Dense(20, activation='relu')(input_vect)\n",
    "    l2 = Dense(20, activation='relu')(l1)\n",
    "    \n",
    "    outRegression = Dense(3, activation='relu')(l2)\n",
    "    # this model maps an input to its reconstruction\n",
    "    return Model(input_vect, outRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dc394dc6-ea10-4a3a-87cf-387353ac0b5a",
    "_uuid": "dd2b60e959d14fa0f3915916051d4830f2bdcfa6"
   },
   "outputs": [],
   "source": [
    "ae1 = xy_regression()\n",
    "ae1.compile(optimizer='adadelta', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8b50fb78-9fd2-48ef-980f-be4c5446db0a",
    "_uuid": "6510271686c74fd56c38de8996a73692303ac761"
   },
   "outputs": [],
   "source": [
    "for i\n",
    "list(zip(np.arange(0,512),np.arange(0,512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "00fe7c73-7fb4-4499-b433-78b19b297495",
    "_kg_hide-output": false,
    "_uuid": "abc00ff7e7714fbbe0ac248aaf37020c2078ce5e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "img = flowerGen[6][0][0]\n",
    "#plt.imshow(img)\n",
    "greyImg = rgb2grey(img).flatten()\n",
    "greyImg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "66635e0e-da60-42ec-b546-5822c6c48ab4",
    "_uuid": "28377269892b78cd3b4be89796a44e77e184f3f5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in flower_dat_gen(0,flowerGen):\n",
    "    print(len(i))\n",
    "    print(i[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e7881ebe-5a39-4ddd-b2a4-dd7719d84e82",
    "_uuid": "e2ed858af738ba2969997aba79d81e7f2a2887e3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flowerGen[6][0][0].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6171a112-abac-455e-9617-6c7f49632756",
    "_uuid": "05c26a9bceb4e43ee4199cce08c2c8b6eb722b9e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow( rgb2grey( flowerGen[6][0][0][0:512][0:512] ),cmap='gray' )\n",
    "flowerGen[6][0][0][0:512][0:512][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "268afe0a-59d3-4027-8114-a0780d93f4e1",
    "_uuid": "af562915e69a8ca21dc3a247c1df1b1b4e9ef5b9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simpleAE(32,512*512)\n",
    "autoencoder.fit_generator(fixed_generator(catGen),samples_per_epoch=12500,verbose=1,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f22d0e06-ebce-4669-a47b-6dd8705651f7",
    "_uuid": "a83af2cb306bb875096b14a14a912d4cdbee2784",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convAutoEnc(encoding_dim = 32, input_dim = 512*512):\n",
    "    input_img = Input(shape=(input_dim,)) \n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "    encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "    # \"decoded\" is the lossy reconstruction of the input\n",
    "    #decoded = Conv2D(3, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    decoded_r = Dense(input_dim,activation='relu')(encoded)\n",
    "    decoded_g = Dense(input_dim,activation='relu')(encoded)\n",
    "    decoded_b = Dense(input_dim,activation='relu')(encoded)\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    return Model(input_img, outputs=[decoded_r,decoded_g,decoded_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8d7abe29-2b9f-48d8-a7ca-75b2a7c94a72",
    "_uuid": "9567f6601780812e029cf0abf839b33a5419d659",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ae1 = convAutoEnc(100)\n",
    "ae1.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "#ae1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "94e9db93-e1f3-41c0-b8f9-70d586661828",
    "_uuid": "9dba25b6aa313b148909166b02b598489a5a2817",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ae1.fit_generator(flower_dat_gen(0,flowerGen),samples_per_epoch=100,verbose=1,epochs=1)\n",
    "#ae1.fit_generator(test1(),samples_per_epoch=100,verbose=1,epochs=1)\n",
    "img = flowerGen[6][0][0]\n",
    "greyImg = rgb2grey(img).flatten()\n",
    "ae1.fit(greyImg.reshape(1,262144), [img[:,:,0].reshape(1,262144),img[:,:,1].reshape(1,262144),img[:,:,2].reshape(1,262144)], epochs=100,batch_size=1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1979c258-d30c-400c-b367-d304be874e74",
    "_uuid": "508e18b1e785e0b77baa0d43fa111fc6a3d8bff6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)\n",
    "visRes( ae1.predict(greyImg.reshape(1,262144)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bba09c3c-833e-4fe2-906d-0a6127ffe704",
    "_uuid": "163d4a49e7c0a24af97d5fcc62d81525166cef14",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(r.reshape(512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5d885025-efe1-4947-95ac-6766f19687ab",
    "_uuid": "a1313da4fbacc3d254a3633ea1274d2af2c748c4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(g.reshape(512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "012f413a-d1a8-4f30-b728-0ceb1bdeebc1",
    "_uuid": "ef655a775c5aed37eb3883ac6ac241cbf59ce71c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(b.reshape(512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2f8c0aa9-6081-40c8-85a3-c18cfd9d6fff",
    "_uuid": "05e9e33831d5f9d9b84e28d0e5cccca604901e32",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow((g/r).reshape(512,512),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "98aaf409-e0ed-4ecf-a184-8c7962b57ede",
    "_uuid": "0b97192b933f8d2d8717dfc3e3cd5cc25a39a1a9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(((r-b)/g).reshape(512,512),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "29b5122b-ab7c-4d76-9f8f-2c8fd80a8d67",
    "_uuid": "4a65b9cc9605f509e156919921b0d91daa1045be",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3f13ffc9-454b-47f9-88ab-a9fcde2e0e69",
    "_uuid": "2c8d993b5a326267cdc0a893b8ff1618a203d3a6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = flowerGen[1][0][0]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)\n",
    "greyImg2 = rgb2grey(img).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5c105456-a9cd-4d57-82c5-207df5a4ca57",
    "_uuid": "978966fb36db5e5b49ba57be9f2803c036f50171",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = ae1.predict(greyImg2.reshape(1,262144))\n",
    "plt.figure(figsize=(10,10))\n",
    "r = np.array(res)[0,:,:][0]\n",
    "g = np.array(res)[1,:,:][0]\n",
    "b = np.array(res)[2,:,:][0]\n",
    "plt.imshow(np.dstack((r,g,b))[0,:,:].reshape((512,512,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6ddd131e-e11f-499b-b679-4854a7003d13",
    "_uuid": "8057dac11a9e9576cd51e2b141ee5c7f97ec7e7c",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
