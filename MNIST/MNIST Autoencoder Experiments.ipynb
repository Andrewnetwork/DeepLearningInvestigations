{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Autoencoder Experiments 1\n",
    "** March 2018 **\n",
    "\n",
    "** Andrew Riberio @ [Github](https://github.com/Andrewnetwork) **\n",
    "\n",
    "This is an interactive notebook for exploring a simple non-convolutional mnist autoencoder. In this lab we look at how an autoencoder is able to build up a representation of the zero digit class. We explore through interactive widgets various properties, including the denosing behavior of our autoencoder ( it makes 0 look more like 0's and other digits look zeroish ).\n",
    "\n",
    "*Note:* This is an interactive notebook and requires you to fork this kernel to run the interactive elements or download a local version of this notebook and run it with jupyter notebooks or jupyter lab. You will need to have the dependencies listed.\n",
    "\n",
    "Resources\n",
    "* https://www.tensorflow.org/get_started/mnist/beginners\n",
    "* https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Libraries and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import losses\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from ipywidgets import interact_manual,interact\n",
    "import pandas as pd\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Start tensorflow session and have keras use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,log_device_placement=True,device_count = {'CPU' : 1, 'GPU' : 1}))\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gathering and Working with MNIST Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Loading the dataset object into the mnist variable and printing the dimensions of the data matrix and label vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n",
    "print(\"Shape of the image data matrix: {0}\".format(mnist.train.images.shape))\n",
    "print(\"Shape of the label data: {0}\".format(mnist.train.labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2.2. Visualizing an image in our training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exampleIndex = 3\n",
    "exImage      = mnist.train.images[exampleIndex ,:]\n",
    "exImageLabel = mnist.train.labels[exampleIndex]\n",
    "plt.imshow(exImage.reshape(28,28),cmap='gray')\n",
    "plt.show()\n",
    "print(\"Image label: {0}\".format(exImageLabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Split images into digit class tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Anomoly Detection for Non-Zero Class Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Compile a simple single layer non-convolutional autoencoder for the digit class 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleAE(encoding_dim = 32, input_dim = 784):\n",
    "\n",
    "    # this is our input placeholder\n",
    "    input_img = Input(shape=(input_dim,))\n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "    encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "    # \"decoded\" is the lossy reconstruction of the input\n",
    "    decoded = Dense(input_dim, activation='relu')(encoded)\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    return Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae1 = simpleAE(64,784)\n",
    "ae1.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Train the autoencoder and log the loss over epoch history. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelURI = \"models/mnist_zero_autoencoder_1_64.h5\"\n",
    "\n",
    "print(\"Loading model...\")\n",
    "\n",
    "try:\n",
    "    # Load model if found. \n",
    "    ae1 = load_model(modelURI)\n",
    "    print(\"Model found and loaded.\")\n",
    "except:\n",
    "    # Train model if model cannot be loaded. \n",
    "    print(\"Model not found. Training model..\")\n",
    "    \n",
    "    history = ae1.fit(digitDict[0], digitDict[0],\n",
    "                    epochs=100,\n",
    "                    batch_size=20,\n",
    "                    shuffle=True,verbose=1)\n",
    "    \n",
    "    # Save our Model\n",
    "    print(\"Model Saved.\")\n",
    "    ae1.save(modelURI)\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Explore trained autoencoder reconstruction results ( Interactive )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispRes1(digitClass=0,nthDigit=0):\n",
    "    actual = digitDict[digitClass][nthDigit,:]\n",
    "    pred = ae1.predict(actual)\n",
    "    res = losses.mean_absolute_error(actual,pred)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    fig.suptitle(\"Mean Absolute Reconstruction Error: {0:.5}%\".format(sess.run(res)[0]*100), fontsize=16,y=0.73)\n",
    "    \n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title(\"Original Image\")\n",
    "    ax1.imshow(actual.reshape(28,28),cmap=\"gray\")\n",
    "    \n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax2.axis('off')\n",
    "    ax2.set_title(\"Reconstructed Image\")\n",
    "    ax2.imshow(pred.reshape(28,28),cmap=\"gray\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "interact_manual(dispRes1,digitClass=(0,9),nthDigit=(0,1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. Reconstruction Error Distributions ( Interactive )\n",
    "We will now explore the reconstruction error distributions over the digit classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classLosses = []\n",
    "for digitClass in range(0,10):\n",
    "    lossTensor = losses.mean_absolute_error(digitDict[digitClass],ae1.predict(digitDict[digitClass]))\n",
    "    res = sess.run(lossTensor)\n",
    "    res.sort()\n",
    "    classLosses.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispDists(digitClass=0):\n",
    "    l = len(classLosses[digitClass])\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.hist(classLosses[digitClass],bins=20,range=(0, 0.125))\n",
    "    plt.show()\n",
    "    \n",
    "interact(dispDists,digitClass=(0,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now plot the histograms of the reconstruction error distributions over the digit classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for digitClass in range(0,10):\n",
    "    l = len(classLosses[digitClass])\n",
    "    plt.legend(['0','1','2','3','4','5','6','7','8','9'], loc='upper right')\n",
    "    plt.hist(classLosses[digitClass],bins=20,range=(0, 0.125))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics for Digit Reconstruction Loss\n",
    "pd.DataFrame(classLosses).transpose().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5. Classify reconstruction loss. \n",
    "**3.5.1. Create loss classifier network architecture **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleNN(encoding_dim = 10, input_dim = 1):\n",
    "\n",
    "    # this is our input placeholder\n",
    "    input_img = Input(shape=(input_dim,))\n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "    encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "    # \"decoded\" is the lossy reconstruction of the input\n",
    "    decoded = Dense(1, activation='sigmoid')(encoded)\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    return Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5.2. Preprocess data for classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Data for Classifier\n",
    "zeroClass = classLosses[0]\n",
    "otherClass = np.concatenate(classLosses[1:10])\n",
    "labels = np.concatenate([np.zeros(len(zeroClass)),np.ones(len(otherClass))])\n",
    "data = np.concatenate([zeroClass,otherClass])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5.3. Train loss classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelURI = \"models/reconstruction_loss_1_64.h5\"\n",
    "\n",
    "print(\"Loading model...\")\n",
    "\n",
    "try:\n",
    "    # Load model if found. \n",
    "    snn = load_model(modelURI)\n",
    "    print(\"Model found and loaded.\")\n",
    "except:\n",
    "    # Train model if model cannot be loaded. \n",
    "    print(\"Model not found. Training model..\")\n",
    "    \n",
    "    snn = simpleNN()\n",
    "    snn.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    history = snn.fit(data, labels,\n",
    "                        epochs=25,\n",
    "                        batch_size=20,\n",
    "                        shuffle=True,verbose=1)\n",
    "    \n",
    "    # Save our Model\n",
    "    print(\"Model Saved.\")\n",
    "    snn.save(modelURI)\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5.4. Visualize results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispRes1(digitClass=0,nthDigit=0):\n",
    "    classificationThresh = 0.5\n",
    "    actual = digitDict[digitClass][nthDigit,:]\n",
    "    pred = ae1.predict(actual)\n",
    "    res = losses.mean_absolute_error(actual,pred)\n",
    "    res = sess.run(res)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    fig.suptitle(\"Mean Absolute Reconstruction Error: {0:.5}%\".format(res[0]*100), fontsize=16,y=0.73)\n",
    "    \n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title(\"Original Image\")\n",
    "    ax1.imshow(actual.reshape(28,28),cmap=\"gray\")\n",
    "    \n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax2.axis('off')\n",
    "    ax2.set_title(\"Reconstructed Image\")\n",
    "    ax2.imshow(pred.reshape(28,28),cmap=\"gray\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    snnRes = snn.predict(res)[0][0]\n",
    "    \n",
    "    if snnRes < classificationThresh:\n",
    "        print(\"Classification 0 : [{0}]\".format( 1-snnRes ))\n",
    "    else:\n",
    "        print(\"Classification ANOMALY : [{0}]\".format( snnRes ))\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "interact_manual(dispRes1,digitClass=(0,9),nthDigit=(0,1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5.5. Evaluate the classification accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificationThresh = 0.5\n",
    "\n",
    "# Get all the training images. \n",
    "actual = mnist.train.images\n",
    "\n",
    "# Pass all the images through the trained zero digit autoencoder. \n",
    "pred = ae1.predict(actual)\n",
    "\n",
    "# Calculuate the reconstruction loss for each image passed through the autoencoder. \n",
    "res = losses.mean_absolute_error(actual,pred)\n",
    "\n",
    "# Use tensorflow to compute the value. \n",
    "res = sess.run(res)\n",
    "\n",
    "# Pass the losses through the loss classifier. \n",
    "snnRes = snn.predict(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tresholdFn( loss ):\n",
    "    if loss < classificationThresh:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "predictions = np.vectorize(tresholdFn)(snnRes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nData = mnist.train.labels.shape[0]\n",
    "nFalsePos = 0\n",
    "falsePosIdxs = []\n",
    "nFalseNeg = 0\n",
    "falseNegIdxs = []\n",
    "\n",
    "for index,prediction,label,in zip(range(nData),predictions,mnist.train.labels):\n",
    "    # Compute the number of false negatives. \n",
    "    if label == 0 and prediction == 1:\n",
    "        nFalseNeg += 1\n",
    "        falseNegIdxs.append(index)\n",
    "        \n",
    "    # Compute the number of false positives. \n",
    "    if label != 0 and prediction == 0:\n",
    "        nFalsePos += 1\n",
    "        falsePosIdxs.append(index)\n",
    "    \n",
    "print(\"Number of false negatives: {0}\".format(nFalseNeg))\n",
    "print(\"Percentage of false negatives: {0:.3}%\".format(nFalseNeg/digitDict[0].shape[0]*100))\n",
    "print(\"---\")\n",
    "print(\"Number of false positives: {0}\".format(nFalsePos))\n",
    "print(\"Percentage of false positives: {0:.6}%\".format(nFalsePos/otherClass.shape[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoResults = ae1.predict(mnist.train.images)\n",
    "lossRes = losses.mean_absolute_error(mnist.train.images,autoResults)\n",
    "lossRes = sess.run(lossRes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize False Positives. False positives are non-zero characters that are classified as zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayFalsePos(idx = 0):\n",
    "    classificationThresh = 0.5\n",
    "    \n",
    "    indexVis = falsePosIdxs[idx]\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    fig.suptitle(\"False Positives - Mean Absolute Reconstruction Error: {0:.5}%\".format(lossRes[indexVis]*100), fontsize=16,y=0.73)\n",
    "    \n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title(\"Original Image\")\n",
    "    ax1.imshow(mnist.train.images[indexVis,:].reshape(28,28),cmap=\"gray\")\n",
    "    \n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax2.axis('off')\n",
    "    ax2.set_title(\"Reconstructed Image\")\n",
    "    ax2.imshow(autoResults[indexVis,:].reshape(28,28),cmap=\"gray\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Absolute index value: {0}.\".format(indexVis))\n",
    "    print(\"Image label: {0}.\".format(mnist.train.labels[indexVis]))\n",
    "        \n",
    "interact(displayFalsePos,idx = (0,len(falsePosIdxs)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayFalseNeg(idx = 0):\n",
    "    classificationThresh = 0.5\n",
    "    \n",
    "    indexVis = falseNegIdxs[idx]\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    fig.suptitle(\"False Negatives - Mean Absolute Reconstruction Error: {0:.5}%\".format(lossRes[indexVis]*100), fontsize=16,y=0.73)\n",
    "    \n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title(\"Original Image\")\n",
    "    ax1.imshow(mnist.train.images[indexVis,:].reshape(28,28),cmap=\"gray\")\n",
    "    \n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax2.axis('off')\n",
    "    ax2.set_title(\"Reconstructed Image\")\n",
    "    ax2.imshow(autoResults[indexVis,:].reshape(28,28),cmap=\"gray\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Absolute index value: {0}.\".format(indexVis))\n",
    "    print(\"Image label: {0}.\".format(mnist.train.labels[indexVis]))\n",
    "        \n",
    "interact(displayFalseNeg,idx = (0,len(falseNegIdxs)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of false negatives: 757\n",
    "Percentage of false negatives: 13.9%\n",
    "---\n",
    "Number of false positives: 394\n",
    "Percentage of false positives: 0.79506%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
